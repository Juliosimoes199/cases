{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65b1bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "011bb2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.json\n",
    "{\n",
    "    \"intents\":\n",
    "    [\n",
    "        {\n",
    "            \"tag\": \"Desing\",\n",
    "            \"input\":[\"desing\", \"Desing\", \"desing\", \n",
    "                     \"design\", \"desing\", \"desing\",\n",
    "                    \"desing\", \"desing\"],\n",
    "            \"output\":[\n",
    "                \"Moda Chique Industria: E-commerce de moda Objetivo: Melhorar a experiencia do usuario e aumentar a taxa de conversao no site. A loja online Moda Chique enfrenta dificuldades com uma taxa de conversao baixa. Muitos usuarios abandonam o site antes de completar a compra. O objetivo do redesign e criar um layout mais intuitivo, atrativo e funcional para melhorar a experiencia do usuario (UX) e incentivar as compras\",\n",
    "                \"Empresa: TechWave Industria: Tecnologia e Inovacao Objetivo: Desenvolver uma identidade visual que transmita inovacao, modernidade e confiança. TechWave e uma startup de tecnologia que esta se lancando no mercado e precisa de uma identidade visual forte e consistente para se destacar e atrair investidores, parceiros e clientes\",\n",
    "                \"Empresa: GreenBrew Coffee Indústria: Alimentos e Bebidas Objetivo: Desenvolver uma embalagem sustentavel que reflita os valores ecologicos e de alta qualidade do cafe organico da empresa. GreenBrew Coffee esta lancando uma nova linha de cafe organico e precisa de uma embalagem que nao so proteja o produto, mas tambem comunique os valores de sustentabilidade e qualidade premium da marca. A embalagem precisa ser pratica, eco-friendly e atrativa para os consumidores.\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"tag\":\"dados\",\n",
    "            \"input\":[\"ciencia de dados\",\" dados\",\"dados\", \"dados\", \"ciencia de dados\", \"dados\",\n",
    "                     \"ciencia de dados\"],\n",
    "            \"output\":[\n",
    "                \"Classificacao de tumor cerebral: O tumor cerebral e considerado uma das doencas mais agressivas, entre criancas  e adultos. Os tumores cerebrais sao responsavel por 85 a 90 por cento de todos os tumores primarios do Sistema Nervoso Central(SNC) A aplicacao de tecnicas de classificacao automatizada usando Machine Learning e Inteligencia Artificial tem consistentemente mostrado maior precisao do que a classificacao manual assim propomos a criacao de um algoritmo de aprendizado profundo utlizando Convolution Neural Network(CNN) link: https://www.kaggle.com/datasets/gonzajl/tumores-cerebrales-mri-dataset\",   \n",
    "                \"Previsao de fraude de cartao de credito: Esse conjunto de dados oferece  uma variedade de atributos valiosos para uma analise abrangente. Ele contem 555.719 instancia e 22 atributos, uma mistura de tipos de dados categoricos e numericos link: https://www.kaggle.com/datasets/kelvimimperial/deteco-de-fraudes-em-cartes-de-credito\",\n",
    "                \"Conjuto de dados de medicamentos desde o uso, efeitos colaterais e avaliacao: Este conjunto de dados, fornece informacoes abrangentes sobre varios medicamentos, incluindo sua composicao, usos, efeitos detalhe do fabricante, avaliacoes de usuarios, etc. link: https://www.kaggle.com/datasets/prathamtripathi/drug-classification\",\n",
    "                \"Previsao de sobrevivencia de pacientes com insuficiencia cardiaca: Esse conjunto de dados contem os prontuarios de 299 pacientes que apresentaram insuficiencia cardiaca, coletados durante o pariodo de seguimento, onde cada perfil de paciente apresenta 13 caracteristicas clinicas\",\n",
    "                \"PNL no Facebook: A onipresenca dos smartphones permite que as pessoas anunciem uma emergencia que estao observando em tempo real. Por causa disso, mais agencias estao interessados em monitorar programaticamente o Facebook(ou seja, organizacoes de ajuda em desastres e agencia de noticias). Mas, nem sempre esta claro se as palavras de uma pessoa estao realmente anunciando um desastre. Link: https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\"\n",
    "                     ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e908ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "resposta = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "230afb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\") as test:\n",
    "    data = json.load(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ffe2941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'Desing',\n",
       "   'input': ['desing',\n",
       "    'Desing',\n",
       "    'desing',\n",
       "    'design',\n",
       "    'desing',\n",
       "    'desing',\n",
       "    'desing',\n",
       "    'desing'],\n",
       "   'output': ['Moda Chique Industria: E-commerce de moda Objetivo: Melhorar a experiencia do usuario e aumentar a taxa de conversao no site. A loja online Moda Chique enfrenta dificuldades com uma taxa de conversao baixa. Muitos usuarios abandonam o site antes de completar a compra. O objetivo do redesign e criar um layout mais intuitivo, atrativo e funcional para melhorar a experiencia do usuario (UX) e incentivar as compras',\n",
       "    'Empresa: TechWave Industria: Tecnologia e Inovacao Objetivo: Desenvolver uma identidade visual que transmita inovacao, modernidade e confianÃ§a. TechWave e uma startup de tecnologia que esta se lancando no mercado e precisa de uma identidade visual forte e consistente para se destacar e atrair investidores, parceiros e clientes',\n",
       "    'Empresa: GreenBrew Coffee IndÃºstria: Alimentos e Bebidas Objetivo: Desenvolver uma embalagem sustentavel que reflita os valores ecologicos e de alta qualidade do cafe organico da empresa. GreenBrew Coffee esta lancando uma nova linha de cafe organico e precisa de uma embalagem que nao so proteja o produto, mas tambem comunique os valores de sustentabilidade e qualidade premium da marca. A embalagem precisa ser pratica, eco-friendly e atrativa para os consumidores.']},\n",
       "  {'tag': 'dados',\n",
       "   'input': ['ciencia de dados',\n",
       "    ' dados',\n",
       "    'dados',\n",
       "    'dados',\n",
       "    'ciencia de dados',\n",
       "    'dados',\n",
       "    'ciencia de dados'],\n",
       "   'output': ['Classificacao de tumor cerebral: O tumor cerebral e considerado uma das doencas mais agressivas, entre criancas  e adultos. Os tumores cerebrais sao responsavel por 85 a 90 por cento de todos os tumores primarios do Sistema Nervoso Central(SNC) A aplicacao de tecnicas de classificacao automatizada usando Machine Learning e Inteligencia Artificial tem consistentemente mostrado maior precisao do que a classificacao manual assim propomos a criacao de um algoritmo de aprendizado profundo utlizando Convolution Neural Network(CNN) link: https://www.kaggle.com/datasets/gonzajl/tumores-cerebrales-mri-dataset',\n",
       "    'Previsao de fraude de cartao de credito: Esse conjunto de dados oferece  uma variedade de atributos valiosos para uma analise abrangente. Ele contem 555.719 instancia e 22 atributos, uma mistura de tipos de dados categoricos e numericos link: https://www.kaggle.com/datasets/kelvimimperial/deteco-de-fraudes-em-cartes-de-credito',\n",
       "    'Conjuto de dados de medicamentos desde o uso, efeitos colaterais e avaliacao: Este conjunto de dados, fornece informacoes abrangentes sobre varios medicamentos, incluindo sua composicao, usos, efeitos detalhe do fabricante, avaliacoes de usuarios, etc. link: https://www.kaggle.com/datasets/prathamtripathi/drug-classification',\n",
       "    'Previsao de sobrevivencia de pacientes com insuficiencia cardiaca: Esse conjunto de dados contem os prontuarios de 299 pacientes que apresentaram insuficiencia cardiaca, coletados durante o pariodo de seguimento, onde cada perfil de paciente apresenta 13 caracteristicas clinicas',\n",
       "    'PNL no Facebook: A onipresenca dos smartphones permite que as pessoas anunciem uma emergencia que estao observando em tempo real. Por causa disso, mais agencias estao interessados em monitorar programaticamente o Facebook(ou seja, organizacoes de ajuda em desastres e agencia de noticias). Mas, nem sempre esta claro se as palavras de uma pessoa estao realmente anunciando um desastre. Link: https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis']}]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f45b7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in data['intents']:\n",
    "    resposta[intent['tag']] = intent['tag']\n",
    "    for row in intent['input']:\n",
    "        X.append(row)\n",
    "        y.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b01a8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'X':X, 'y':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54946106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desing</td>\n",
       "      <td>Desing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desing</td>\n",
       "      <td>Desing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desing</td>\n",
       "      <td>Desing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>design</td>\n",
       "      <td>Desing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>desing</td>\n",
       "      <td>Desing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>desing</td>\n",
       "      <td>Desing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>desing</td>\n",
       "      <td>Desing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>desing</td>\n",
       "      <td>Desing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ciencia de dados</td>\n",
       "      <td>dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dados</td>\n",
       "      <td>dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dados</td>\n",
       "      <td>dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dados</td>\n",
       "      <td>dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ciencia de dados</td>\n",
       "      <td>dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dados</td>\n",
       "      <td>dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ciencia de dados</td>\n",
       "      <td>dados</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X       y\n",
       "0             desing  Desing\n",
       "1             Desing  Desing\n",
       "2             desing  Desing\n",
       "3             design  Desing\n",
       "4             desing  Desing\n",
       "5             desing  Desing\n",
       "6             desing  Desing\n",
       "7             desing  Desing\n",
       "8   ciencia de dados   dados\n",
       "9              dados   dados\n",
       "10             dados   dados\n",
       "11             dados   dados\n",
       "12  ciencia de dados   dados\n",
       "13             dados   dados\n",
       "14  ciencia de dados   dados"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf29da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f165c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(df['X'])\n",
    "train = tokenizer.texts_to_sequences(df['X'])\n",
    "Xtrain = pad_sequences(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cdf7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "465e425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20769534",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = le.fit_transform(df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1aa57a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = Xtrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7f5f36e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b73931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = len(tokenizer.word_index)\n",
    "output_length = le.classes_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c6fd8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Flatten, Dense, Embedding, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0979f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(shape=(input_shape, ))\n",
    "x = Embedding(vocabulary + 1, 10)(i)\n",
    "x = LSTM(10, return_sequences=True)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(output_length, activation='softmax')(x)\n",
    "model = Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "67e6f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06e92d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5537 - loss: 0.6923\n",
      "Epoch 2/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7108 - loss: 0.6890 \n",
      "Epoch 3/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6720 - loss: 0.6866 \n",
      "Epoch 4/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.6773 \n",
      "Epoch 5/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.6690 \n",
      "Epoch 6/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.6651 \n",
      "Epoch 7/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5470 - loss: 0.6777     \n",
      "Epoch 8/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.6469 \n",
      "Epoch 9/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7849 - loss: 0.6444\n",
      "Epoch 10/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6396 - loss: 0.6448 \n",
      "Epoch 11/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.6008 \n",
      "Epoch 12/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7183 - loss: 0.6008 \n",
      "Epoch 13/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8220 - loss: 0.5499 \n",
      "Epoch 14/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6275 - loss: 0.5819     \n",
      "Epoch 15/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8873 - loss: 0.4748 \n",
      "Epoch 16/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6886 - loss: 0.5175 \n",
      "Epoch 17/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7929 - loss: 0.4517 \n",
      "Epoch 18/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7604 - loss: 0.4288 \n",
      "Epoch 19/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.4202 \n",
      "Epoch 20/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7841 - loss: 0.3884 \n",
      "Epoch 21/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.3696 \n",
      "Epoch 22/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3550 \n",
      "Epoch 23/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3517 \n",
      "Epoch 24/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2466 \n",
      "Epoch 25/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2307 \n",
      "Epoch 26/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2130 \n",
      "Epoch 27/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2461 \n",
      "Epoch 28/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1832 \n",
      "Epoch 29/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1798 \n",
      "Epoch 30/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1268 \n",
      "Epoch 31/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1720 \n",
      "Epoch 32/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1040 \n",
      "Epoch 33/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1235 \n",
      "Epoch 34/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1065 \n",
      "Epoch 35/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0836 \n",
      "Epoch 36/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0779 \n",
      "Epoch 37/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0713 \n",
      "Epoch 38/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0680\n",
      "Epoch 39/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0569 \n",
      "Epoch 40/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0624  \n",
      "Epoch 41/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0428 \n",
      "Epoch 42/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0443 \n",
      "Epoch 43/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0362 \n",
      "Epoch 44/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0360 \n",
      "Epoch 45/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0416 \n",
      "Epoch 46/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0390 \n",
      "Epoch 47/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0305 \n",
      "Epoch 48/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0211 \n",
      "Epoch 49/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0247 \n",
      "Epoch 50/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0253 \n",
      "Epoch 51/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0249 \n",
      "Epoch 52/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0200 \n",
      "Epoch 53/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0232 \n",
      "Epoch 54/54\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0222 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2242ae0a190>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, epochs=54, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2b3ce79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área de interesse: design\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step\n",
      "Empresa: TechWave Industria: Tecnologia e Inovacao Objetivo: Desenvolver uma identidade visual que transmita inovacao, modernidade e confianÃ§a. TechWave e uma startup de tecnologia que esta se lancando no mercado e precisa de uma identidade visual forte e consistente para se destacar e atrair investidores, parceiros e clientes\n",
      "Área de interesse: dados\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Classificacao de tumor cerebral: O tumor cerebral e considerado uma das doencas mais agressivas, entre criancas  e adultos. Os tumores cerebrais sao responsavel por 85 a 90 por cento de todos os tumores primarios do Sistema Nervoso Central(SNC) A aplicacao de tecnicas de classificacao automatizada usando Machine Learning e Inteligencia Artificial tem consistentemente mostrado maior precisao do que a classificacao manual assim propomos a criacao de um algoritmo de aprendizado profundo utlizando Convolution Neural Network(CNN) link: https://www.kaggle.com/datasets/gonzajl/tumores-cerebrales-mri-dataset\n",
      "Área de interesse: sair\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    text = []\n",
    "    predict = input('Área de interesse: ')\n",
    "    time.sleep(0.6)\n",
    "    if predict == 'sair':\n",
    "        break\n",
    "    predict = [letters.lower() for letters in predict if letters not in string.punctuation]\n",
    "    predict = ''.join(predict)\n",
    "    text.append(predict)\n",
    "\n",
    "    predict = tokenizer.texts_to_sequences(text)\n",
    "    predict = np.array(predict).reshape(-1)\n",
    "    predict = pad_sequences([predict], input_shape)\n",
    "\n",
    "    output = model.predict(predict)\n",
    "    output = output.argmax()\n",
    "\n",
    "    resp = le.inverse_transform([output])[0]\n",
    "    if resp == 'Desing':\n",
    "        saida =  data['intents']\n",
    "        aleatorio = random.randint(0, 3)\n",
    "        print(saida[0]['output'][aleatorio])\n",
    "    elif resp == 'dados':\n",
    "        saida =  data['intents']\n",
    "        aleatorio = random.randint(0, 2)\n",
    "        print(saida[1]['output'][aleatorio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e92e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
